{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from training_flags import *\n",
    "from Utilities.evaluation_utils import *\n",
    "from DataPreparation.dataset_preparation import get_catsvsdogs_dataset\n",
    "from GraphBuilder.model import Model\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Loading the Dataset\n",
    "\n",
    "### Getting started guide\n",
    "* Set the data directory to the path where <b>either</b>: <br>\n",
    "1- The following paths exist: trainset/Cat/, trainset/Dog/, testset/test/ <br>\n",
    "2- The following numpy files exist: train_dataset.npy, train_labels.npy, X_test.npy <br>\n",
    "* Determine the train-validation split ratio. A \"validation_split\" of 0.2 means that 20% of train_dataset will be used for validation and 80% of train_dataset will be used for training.<br>\n",
    "* (Optional) Set a seed (\"split_seed\") for how validation and training get split up if you want to always split them the same way.<br>\n",
    "\n",
    "### (Optional) Using another dataset\n",
    "* If you want to read another dataset (other than catsvsdogs), you can try modifying dataset_preparation.py<br>\n",
    "* If dataset images are not of size (64, 64, 3), or if you have more than 2 classes, you can change these parameters in training_flags.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_dir = 'Dataset/'\n",
    "validation_split = 0.025\n",
    "# split_seed = 6135"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and check the size of the dataset\n",
    "The data loaded here is used in test mode later. For training, data is loaded internally by the model object using this same get_catsvsdogs_dataset function defined in dataset_preparation.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size:  (19499, 64, 64, 3)\n",
      "Train labels size:  (19499,)\n",
      "Val data size:  (499, 64, 64, 3)\n",
      "Val labels size:  (499,)\n",
      "Test data size:  (4999, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, X_train_moments = get_catsvsdogs_dataset(data_dir,\n",
    "                                        validation_split, split_seed, normalize_train=True)\n",
    "mean_img, std_img = X_train_moments\n",
    "print('Train data size: ', X_train.shape)\n",
    "print('Train labels size: ', y_train.shape)\n",
    "print('Val data size: ', X_val.shape)\n",
    "print('Val labels size: ', y_val.shape)\n",
    "print('Test data size: ', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the Hyperparameters\n",
    "* Change which model to use by changing \"model\" flag in training_flags.py (<b>NOTE:</b> Be sure to restart Jupyter Notebook Kernel for your change to take place (Shortcut: Press 0 twice))<br>\n",
    "* Set the hyperparameters for training/loading the model by modifying hyperparameters \"hparams\" below.<br>\n",
    "* We have provided two sets of hyperparameter for VGG19 and Wide28-10 that worked well for catsvsdogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did nothing.\n"
     ]
    }
   ],
   "source": [
    "### Good Hyperparameters for VGG19\n",
    "if FLAGS.model is 'VGG19':\n",
    "    hparams = tf.contrib.training.HParams(\n",
    "        data_dir=data_dir,\n",
    "        validation_split=validation_split,\n",
    "        split_seed=split_seed,\n",
    "        num_steps = 55000,\n",
    "        lr = 3e-3, # 3e-3, 2e-4\n",
    "        train_batch_size=256,\n",
    "        eval_batch_size=128,\n",
    "        dropout_probability=0.5,\n",
    "        resume_training = True,\n",
    "        optimizer='Momentum',\n",
    "        cosine_lr = False,\n",
    "        l2_scale = 3e-4, # 3e-4, 8e-4\n",
    "        lr_decay_factor = 0.1,\n",
    "        decay_steps = [40000, 60000]\n",
    "        )\n",
    "    print('VGG19 hyperparameters set.')\n",
    "else:\n",
    "    print('Did nothing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wide28_10 hyperparameters set.\n"
     ]
    }
   ],
   "source": [
    "### Good Hyperparameters for Wide28-10\n",
    "if FLAGS.model is 'Wide28_10':\n",
    "    hparams = tf.contrib.training.HParams(\n",
    "        data_dir=data_dir,\n",
    "        validation_split=validation_split,\n",
    "        split_seed=split_seed,\n",
    "        num_steps=75000,\n",
    "        lr=1e-2,\n",
    "        train_batch_size=50,\n",
    "        eval_batch_size=50,\n",
    "        dropout_probability=0.5,\n",
    "        resume_training=False,\n",
    "        optimizer='Momentum',\n",
    "        cosine_lr=False,\n",
    "        l2_scale=1e-4,\n",
    "        lr_decay_factor=0.1,\n",
    "        decay_steps=[30000, 55000]\n",
    "        )\n",
    "    print('Wide28_10 hyperparameters set.')\n",
    "else:\n",
    "    print('Did nothing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Setting up the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter search (Optional)\n",
    "Random search for finding the optimal hyperparameters. If you are using the set of hyperparameters provided above, you can skip this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr: 0.051541\n",
      "l2 reg: 0.000000\n",
      "~~~ Training with /gpu:0 ~~~\n",
      "Model: Wide28_10\n",
      "Number of parameters: 36.22M\n",
      "Training minibatch size: 50\n",
      "Validation minibatch size: 50\n",
      "Using data augmentation: True\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "(05:59:50 PM) Iteration 0:\n",
      "Training data: loss= 5.3207, accuracy 44.00%\n",
      "Validation data: loss= 539812421384743984708976640.0000, accuracy 42.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "(06:03:37 PM) Iteration 250:\n",
      "Training data: loss= 0.6983, accuracy 52.00%\n",
      "Validation data: loss= 0.6608, accuracy 50.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "(06:07:24 PM) Iteration 500:\n",
      "Training data: loss= 0.6782, accuracy 62.00%\n",
      "Validation data: loss= 0.6723, accuracy 66.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "(06:11:11 PM) Iteration 750:\n",
      "Training data: loss= 0.6942, accuracy 48.00%\n",
      "Validation data: loss= 0.6871, accuracy 54.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "(06:14:58 PM) Iteration 1000:\n",
      "Training data: loss= 0.6701, accuracy 62.00%\n",
      "Validation data: loss= 0.6359, accuracy 56.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "(06:18:44 PM) Iteration 1250:\n",
      "Training data: loss= 0.6734, accuracy 54.00%\n",
      "Validation data: loss= 0.5895, accuracy 56.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "(06:22:31 PM) Iteration 1500:\n",
      "Training data: loss= 0.6602, accuracy 58.00%\n",
      "Validation data: loss= 0.6540, accuracy 60.00%\n",
      "(lr=0.051541)\n",
      "\n",
      "lr: 0.018895\n",
      "l2 reg: 0.000000\n",
      "~~~ Training with /gpu:0 ~~~\n",
      "Model: Wide28_10\n",
      "Number of parameters: 36.22M\n",
      "Training minibatch size: 50\n",
      "Validation minibatch size: 50\n",
      "Using data augmentation: True\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "(06:23:13 PM) Iteration 0:\n",
      "Training data: loss= 3.5450, accuracy 42.00%\n",
      "Validation data: loss= 110410934559870812160.0000, accuracy 58.00%\n",
      "(lr=0.018895)\n",
      "\n",
      "(06:27:02 PM) Iteration 250:\n",
      "Training data: loss= 0.7162, accuracy 42.00%\n",
      "Validation data: loss= 0.6871, accuracy 52.00%\n",
      "(lr=0.018895)\n",
      "\n",
      "(06:30:49 PM) Iteration 500:\n",
      "Training data: loss= 0.6508, accuracy 64.00%\n",
      "Validation data: loss= 0.8198, accuracy 34.00%\n",
      "(lr=0.018895)\n",
      "\n",
      "(06:34:36 PM) Iteration 750:\n",
      "Training data: loss= 0.6878, accuracy 48.00%\n",
      "Validation data: loss= 0.6745, accuracy 60.00%\n",
      "(lr=0.018895)\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-229e3e43c89f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'lr: %.6f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'l2 reg: %.6f'\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ml2_scale\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Soroush\\IFT6135_local\\Assignment1\\Kaggle\\Model\\GraphBuilder\\model.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    106\u001b[0m                                 \u001b[0mfeed_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_train_mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train_mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                                 \u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_top1_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                                 \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_error_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                                 \u001b[1;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_every\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\toolkits.win\\anaconda3-5.2.0\\envs\\dlwin36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # hparams.l2_scale = 1e-12\n",
    "# # hparams.num_steps = 1510\n",
    "# # np.random.seed()\n",
    "# for _ in range(100):\n",
    "# #     hparams.lr = 10 ** np.random.uniform(-5, 0)\n",
    "# #     hparams.l2_scale = 10 ** np.random.uniform(-5, -2)\n",
    "#     tf.reset_default_graph()\n",
    "#     model = Model(hparams)\n",
    "#     print('lr: %.6f'%hparams.lr)\n",
    "#     print('l2 reg: %.6f'%hparams.l2_scale)\n",
    "#     model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train (or Load) the model\n",
    "Trains or loads the model depending on whether \"hparams.resume_training\" is True or False. If \"hparams.resume_training\" is True, it will load the model from \"FLAGS.load_dir\" directory and continue training until \"hparams.num_steps\" is reached."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "hparams.lr = 1e-4\n",
    "model = Model(hparams) # Initialize Model object\n",
    "train_history = model.train() # Start training\n",
    "print('Training done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Inference Accuracy\n",
    "Evaluates final accuracies on train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_scores = model.test(X_train)\n",
    "print('Train')\n",
    "print('Accuracy: %.3f%%' % ((1-top1_error(train_scores, y_train)) * 100))\n",
    "print('-------------')\n",
    "val_scores = model.test(X_val)\n",
    "print('Validation')\n",
    "print('Accuracy: %.3f%%' % ((1-top1_error(val_scores, y_val)) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training history as a csv file\n",
    "save_history(train_history, hparams.num_steps, FLAGS.print_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update(plt.rcParamsDefault)\n",
    "steps = FLAGS.print_every * np.arange(len(train_history['lr_hist']))\n",
    "fig, axes = plt.subplots(3, 1)\n",
    "for i, measure in enumerate(['loss', 'error']):\n",
    "    measure_figures = {'train':train_history['train_'+measure+'_hist'],\n",
    "                    'val':train_history['val_'+measure+'_hist']}\n",
    "    if measure == 'error': # convert top 1 error to accuracy\n",
    "        measure_figures['train'] = [1-error for error in measure_figures['train']]\n",
    "        measure_figures['val'] = [1-error for error in measure_figures['val']]\n",
    "        \n",
    "    ax = axes[i]\n",
    "    for data_name, measure_history in list(measure_figures.items()):\n",
    "        ax.plot(steps, measure_history, label = data_name, rasterized=True)\n",
    "        ax.set_xlabel('# iterations', size=14)\n",
    "        ax.legend(loc='upper center', ncol=2)\n",
    "        if measure == 'loss':\n",
    "            ax.set_ylabel('Loss', size=14)\n",
    "        else:\n",
    "            ax.set_ylabel('Accuracy', size=14)\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(steps, train_history['lr_hist'], label = 'Learning Rate', rasterized=True)\n",
    "ax.set_xlabel('# iterations', size=14)\n",
    "\n",
    "ax.set_ylabel('Learning Rate', size=14)\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle('Convergence', size=20)\n",
    "axes[0].title.set_text('Train and Validation loss during training')\n",
    "axes[1].title.set_text('Train and Validation accuracy during training')\n",
    "axes[2].title.set_text('Learning rate schedule during training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Visualizing Classification results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Random Correct Classifications on Validation Set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Correct classifications\n",
    "num_sample = 10\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [50, 50]\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "predictions = softmax(val_scores)\n",
    "\n",
    "y_preds = np.argmax(predictions, axis=1)\n",
    "correct_preds = np.equal(y_preds, y_val)\n",
    "correct_probs = predictions[correct_preds]\n",
    "correct_images = X_val[correct_preds]\n",
    "\n",
    "correct_preds = {'cat':[], 'dog':[]}\n",
    "ind = np.arange(correct_images.shape[0])\n",
    "ind_cat = ind[correct_probs[:,0] > 0.5]\n",
    "ind_dog = ind[correct_probs[:,1] > 0.5]\n",
    "np.random.shuffle(ind_cat)\n",
    "np.random.shuffle(ind_dog)\n",
    "\n",
    "correct_preds['cat'] = ind_cat[:num_sample]\n",
    "correct_preds['dog'] = ind_dog[:num_sample]\n",
    "\n",
    "classes = ['cat', 'dog']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = num_sample\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = correct_preds[cls]\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        ax = plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        ax.set_title(cls+'ness score:'+str(np.round(correct_probs[idx,y], 4)))\n",
    "        plt.imshow((mean_img+(std_img*correct_images[idx])).astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Most Certain Misclassifications on Validation Set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_wrong = 25\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 12}\n",
    "plt.rc('font', **font)\n",
    "\n",
    "y_preds = np.argmax(predictions, axis=1)\n",
    "wrong_preds = ~np.equal(y_preds, y_val)\n",
    "wrong_probs = predictions[wrong_preds]\n",
    "wrong_images = X_val[wrong_preds]\n",
    "\n",
    "top_wrong_preds = {'cat':[], 'dog':[]}\n",
    "top_wrong_preds['cat'] = wrong_probs[:,0].argsort()[-top_wrong:][::-1]\n",
    "top_wrong_preds['dog'] = wrong_probs[:,1].argsort()[-top_wrong:][::-1]\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 60]\n",
    "\n",
    "classes = ['cat', 'dog']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = top_wrong\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = top_wrong_preds[cls]\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        ax = plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        ax.set_title(str(np.round(wrong_probs[idx,y], 4)))\n",
    "        img = (mean_img+(std_img*wrong_images[idx])).astype('uint8')\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls+'ness probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <b>Most Uncertain Misclassifications on Validation Set</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Most uncertain misclassifications\n",
    "top_wrong = 10\n",
    "\n",
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 22}\n",
    "plt.rc('font', **font)\n",
    "plt.rcParams['figure.figsize'] = [50, 50]\n",
    "\n",
    "y_preds = np.argmax(predictions, axis=1)\n",
    "wrong_preds = ~np.equal(y_preds, y_val)\n",
    "wrong_probs = predictions[wrong_preds]\n",
    "wrong_images = X_val[wrong_preds]\n",
    "\n",
    "editted_wrong_probs = wrong_probs.copy()\n",
    "editted_wrong_probs[editted_wrong_probs<0.5] = 100\n",
    "top_wrong_preds = {'cat':[], 'dog':[]}\n",
    "top_wrong_preds['cat'] = (editted_wrong_probs[:,0]-0.5).argsort()[:top_wrong]\n",
    "top_wrong_preds['dog'] = (editted_wrong_probs[:,1]-0.5).argsort()[:top_wrong]\n",
    "\n",
    "classes = ['cat', 'dog']\n",
    "num_classes = len(classes)\n",
    "samples_per_class = top_wrong\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = top_wrong_preds[cls]\n",
    "    for i, idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        ax = plt.subplot(samples_per_class, num_classes, plt_idx)\n",
    "        ax.set_title(str(np.round(wrong_probs[idx,y], 4)))\n",
    "        plt.imshow((mean_img+(std_img*wrong_images[idx])).astype('uint8'))\n",
    "        plt.axis('off')\n",
    "        if i == 0:\n",
    "            plt.title(cls+'ness probability')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4- Classify Test Dataset\n",
    "Get logits for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores = model.test(X_test)\n",
    "print('Test set logits computed.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store predictions for test dataset as csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(test_scores, axis=1)\n",
    "labels = ['Cat', 'Dog']\n",
    "save_predictions(predictions, labels, hparams.num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store probabilities for each label as csv file (for later use in ensembling models)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_probabilities = softmax(test_scores)\n",
    "save_probabilities(test_probabilities, labels, hparams.num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_probabilities = softmax(val_scores)\n",
    "save_probabilities(val_probabilities, labels, f'val_{hparams.num_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
